# <div  align="center">**一文综述-推荐系统知识体系总览**</div>


<div  align="center">李中杰</div>

---
#**本文结构**
<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/mfurz8powrfpqkic7ci5iqrw/image_1bc7rtle7rbn144s1bbhrbkh2p8s.png" width="900" height="900" alt="Item-based filtering" /></div>

#1.	**推荐系统的3个W**
##1.1	**是什么(What is it？)**
>**推荐系统** 就是根据用户的历史行为、社交关系、兴趣点、所处上下文环境等信息去判断用户当前需要或感兴趣的物品/服务的一类应用。
##1.2	**为什么(Why is that？)**
为什么我们要用到推荐系统呢？随着信息技术和互联网的发展，人类从信息匮乏时代走向了**信息过载（Information Overload）**时代。对于信息消费者，也就是用户，从大量信息中找到自己感兴趣的信息变得越来越困难；对于信息生产者，让自己生产的信息在众多信息中脱颖而出也变得越来越困难。推荐系统正是为了解决这一矛盾而应运而生的。推荐系统的主要任务就是联系用户和信息。对用户而言，推荐系统能帮助用户找到喜欢的物品/服务，帮忙进行决策，发现用户可能喜欢的新事物；对商家而言，推荐系统可以给用户提供个性化的服务，提高用户信任度和粘性，增加营收。我们可以通过一组数据了解推荐系统的价值：

>* **Netflix**：2/3 被观看的电影来自推荐
* **Google新闻**：38%的点击量来自推荐
* **Amazon**：35%的销量来自推荐

当你看到这些数字，推荐系统的价值就不言而喻了吧？
##1.3  **用在哪(Where to apply？)**
在这个信息爆炸的时代，信息过载问题催生了推荐系统在我们日常生活中方方面面的渗透：电子商务、电影或视频网站、个性化音乐网络电台、社交网络、个性化阅读、基于位置的服务、个性化邮件、个性化广告……在你逛淘宝、订外卖、听网络电台、看美剧、查邮件、淘攻略的时候，推荐系统在你不知不觉中将你可能感兴趣的内容推送给你。**和搜索引擎不同，个性化推荐系统需要依赖用户的行为数据**，一般都是作为一个应用存在于不同网站之中。在互联网的各大网站中都可以看到推荐系统的影子。例如都是逛淘宝，女同胞们和男同胞们看到的网页界面会有所不同。
 以淘宝为例，本人（女）看到的淘宝界面：

 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/2mm0w8t5cxbs5wtpomkhuxu3/image_1bc7noi0h17q61mqr605pnfics5o.png" width="400" height="400" alt="Item-based filtering" /></div>

男票看到的淘宝界面：
 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/d8ul1jur4fsil16bqtjueq6m/1.jpg" width="400" height="400" alt="Item-based filtering" /></div>
 
每个人的喜好不同，在页面上浏览的内容就不同，我们的每一次点击和搜索都会在网站上留下记录。淘宝的**推荐系统正是通过分析大量我们平时浏览商品的行为日志，推测出我们的喜好，从而给不同用户提供不同的个性化界面，来提高网站的点击率和转化率**。

---
#2.	**推荐系统的结构（Structure）**
<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/f42j2zy8xoddkd4aho3itgug/image_1bc7oua8o3uh1fstug21acr1cra65.png" width="800" height="400" alt="Item-based filtering" /></div>

>尽管不同的网站使用不同的推荐系统，但是总的来说，几乎所有的推荐系统的结构都是类似的，都由**线上和线下**两部分组成。线下部分包括后台的日志系统和推荐算法系统，线上部分就是我们看到的前台页面展示。线下部分通过学习用户资料和行为日志建立模型，在新的上下文背景之下，计算相应的推荐内容，呈现于线上页面中。

---

#3.	**推荐引擎算法（Algorithm）**
##3.1	**协同过滤推荐算法**
###3.1.1 **关系矩阵与矩阵计算**
>在一个推荐系统中，存在三类关系：用户与用户（U-U矩阵）、物品与物品（V-V矩阵）和用户与物品（U-V矩阵）。

 - **U-U矩阵**
  - **算法原理**
在基于用户相似度的协同过滤中，用户相似度的计算是基本前提。Pearson相关系数主要用于度量两个变量*i*和*j*之间的相关性，取值范围是+1（强正相关）到-1（强负相关），计算公式为：
$${\rm{sim\_user\_value}}(i,j) = \frac{{{\sum _{c \in {I_{ij}}}}({r_{i,c}} - \overline {{r_i}} )({r_{j,c}} - \overline {{r_j}} )}}{{\sqrt {{\sum _{c \in {I_i}}}{{({r_{i,c}} - \overline {{r_i}} )}^2}} \sqrt {{\sum _{c \in {I_j}}}{{({r_{j,c}} - \overline {{r_j}} )}^2}} }}$$
式中，${I_{ij}}$为用户$i$和$j$共同评价过的物品的集合，$c$是这个集合中的物品元素，${r_{i,c}}$是用户$i$对物品$c$的评价值，${r_{j,c}}$为用户$j$对物品$% 
c$的评价值，$\overline {{r_i}} $和$\overline {{r_j}} $分别表示用户$i$和$j$对物品的平均评价值。

  - **算法流程**
算法输入：用户行为日志。
算法输出：基于协同的用户相似度矩阵。
A.	从用户行为日志中获取用户与物品之间的关系数据，即用户对物品的评分数据。
B.	对于n个用户，依次计算用户1与其他n-1个用户的相似度；再计算用户2与其他n-2个用户的相似度。对于其中任意两个用户$i$和$j$：
a)	查找两个用户共同评价过的物品集$%
{I_{ij}}$；
b)	分别计算用户$i$和$j$对物品的平均评价$% 
\overline {{r_i}} $和$\overline {{r_j}} $；
c)	计算用户间相似度，得到用户$% 
i$和$j$的相似度。
C.	将计算得到的相似度结果存储于数据库中。

 - **V-V矩阵**
   - **算法原理**
在基于物品相似度的协同过滤中，物品相似度的计算是基本前提。将物品的评价数值抽象为n维用户空间中的列向量$%
{x_i}$和${x_j}$，使用修正的余弦相似度，计算公式为：
$${\rm{sim\_item\_value}}({x_i},{x_j}) = \frac{{{\sum _{u \in {U_{{x_i}{x_j}}}}}({r_{u,{x_i}}} - \overline {{r_{{x_i}}}} )({r_{u,{x_j}}} - \overline {{r_{{x_j}}}} )}}{{\sqrt {{\sum _{u \in {U_{{x_i}{x_j}}}}}{{({r_{u,{x_i}}} - \overline {{r_{{x_i}}}} )}^2}} \sqrt {{\sum _{u \in {U_{{x_i}{x_j}}}}}{{({r_{u,{x_j}}} - \overline {{r_{{x_j}}}} )}^2}} }}$$
式中，${U_{{x_i}{x_j}}}$为对物品${x_i}$和${x_j}$共同评价过的用户的集合， 是用户${u}$对物品${x_i}$的评价值，$\overline {{r_{{x_i}}}} $和$\overline {{r_{{x_j}}}}$分别表示用户对物品${x_i}$和${x_j}$的平均评价值。

  - **算法流程**
算法输入：用户行为日志。
算法输出：基于协同的物品相似度矩阵。
A.	从用户行为日志中获取用户与物品之间的关系数据，即用户对物品的评分数据。
B.	对于n个物品，依次计算物品1与其他n-1个物品的相似度；再计算物品2与其他n-2个物品的相似度。对于其中任意两个物品${i}$和${j}$：
a)	查找对物品${i}$和${j}$共同评价过的用户集${U_{ij}}$；
b)	分别计算用户对物品${i}$和${j}$的平均评价$\overline {{r_i}}$和$\overline {{r_j}} $；
c)	计算物品间相似度，得到物品${i}$和${j}$的相似度。
C.	将计算得到的相似度结果存储于数据库中。  

 - **U-V矩阵**
在真实的推荐系统中，一方面U-V矩阵的行列数会随着用户和物品数量变得庞大，另一方面，因为用户实际上只能对有限数量的物品做出评价，所以U-V矩阵的内部会非常稀疏。系统在直接处理这些庞大稀疏矩阵时，耗费的时间、内存和计算资源都十分巨大。因此需要采取降低计算复杂度的方法。矩阵分解技术是一种有效降低矩阵计算复杂的方法，它的实质是将高维矩阵进行有效降维。

  - **奇异值分解（SVD）**
SVD将给定矩阵分解为3个矩阵的乘积：
$$M = U\Sigma {V^T}$$
式中，矩阵$\Sigma$为对角阵，其对角线上的值$\sigma$ 为矩阵M的奇异值，按大小排列，代表着矩阵M的重要特征。将SVD用在推荐系统上，其意义是将一个系数的评分矩阵M分解为表示用户特性的U矩阵，表示物品特性的V矩阵，以及表示用户和物品相关性的$\Sigma$矩阵。

  - **主成分分析（PCA）**
在推荐系统中，对于有较多属性的物品（物品的信息用向量${\bf{m}}[{i_1},{i_2},...,{i_n}]$ 表示）可用PCA处理进行降维，将m×n的物品矩阵转化为m×k的新矩阵。

###3.1.2 **基于记忆的协同过滤算法**

1.**基于用户的协同过滤算法**
>**基于用户的协同过滤（user-based collaborative filtering）**算法是推荐系统中最古老的算法，产生于1992年，最初应用于邮件过滤系统，1994年被GroupLens用于新闻过滤。在此之后直到2000年，该算法都是推荐系统领域最著名的算法。

- **算法原理**
 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/czupsupev75sab0zrtp8rlwx/User.jpg" width="300" height="300" alt="User-based filtering" /></div>

 什么是基于用户的协同过滤算法？举个简单的例子，我们知道樱桃小丸子喜欢葡萄、草莓、西瓜和橘子，而我们通过某种方法了解到小丸子和花伦有相似的喜好，所以我们会把小丸子喜欢的而花伦还未选择的水果（葡萄和橘子）推荐给花伦。
通过上面的例子我们可以做出如下总结：假设用户为${U_i}(i = 1,2,...,n)$，物品${M_j}(j = 1,2,...,m)$，${U_i}$对${M_j}$的评分为${r_{i,j}}$，基于用户的协同过滤算法主要包含以下两个步骤：

 A.	搜集用户和物品的历史信息，计算用户u和其他用户的相似度${\rm{Sim}}(u,{N_i})$，找到和目标用户Ui兴趣相似的用户集合${N(u)}$；
B.	找到这个集合中用户喜欢的，且目标用户还没有听说过的物品推荐给目标用户。
基于用户的协同过滤子引擎，通过下面的公式来计算用户对物品的喜好程度：
$${p_{uj}} = \frac{{\sum\limits_{{N_i} \in N(u)}^{} {Sim(u,{N_i}) \times {r_{{N_{i,j}}}}} }}{{\sum\limits_{{N_i} \in N(u)}^{} {Sim(u,{N_i})} }}$$
式中，${p_{uj}}$表示用户${u}$对物品${j}$的喜好程度，${r_{{N_{i,j}}}}$表示用户${N_i}$对物品${j}$的评价，${\rm{Sim}}(u,{N_i})$表示用户${u}$和用户${N_i}$的相似度。最后根据${p_{uj}}$来对候选物品进行排序，为用户推荐分值最高的Top-N个物品。

- **算法流程**
 算法输入：用户行为日志，基于协同的用户相似性矩阵。
 算法输出：初始推荐结果
 
 A.	访问用户行为日志，获取近期变化的用户ID集合${U}$。
B.	针对集合${U}$中每个用户${u}$：
a)	访问用户相似矩阵，获取与用户相似的用户合集${N(u)}$。
b)	对于${N(u)}$中的每一个用户${u_i}$：
			获取与用户ui有关联的物品合集${M_{ui}}$。
			针对物品合集${M_{ui}}$中的每个物品，计算用户偏好值。
c)	对集${M(u)}$中的所有物品进行按照用户偏好进行加权、去重、排序。
d)	取Top-N个物品，为每个物品赋予解释。
e)	保存Top-N个物品到初始推荐列表中。

- **适用性**
由于需计算用户相似度矩阵，基于用户的协同过滤算法适用于用户较少的场合；
由于时效性较强，该方法适用于用户个性化兴趣不太明显的领域。
 
 
2.**基于物品的协同过滤算法**
>**基于物品的协同过滤（item-based collaborative filtering）**算法是目前业界应用最多的算法。无论是亚马逊网，还是Netflix、Hulu、Youtube，其推荐算法的基础都是该算法。

 - **算法原理**
 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/fgmww8psa64kdjubfey2wlid/Item.jpg" width="300" height="300" alt="Item-based filtering" /></div>

 基于物品的协同过滤算法给用户推荐那些和他们之前喜欢的物品相似的物品。比如，我们知道樱桃小丸子和小玉都喜欢葡萄和西瓜，那么我们就认为葡萄和西瓜有较高的相似度，在花伦选择了西瓜的情况下，我们会把葡萄推荐给花伦。ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度。该算法认为，物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B。
假设用户为${U_i}(i = 1,2,...,n)$，物品${M_j}(j = 1,2,...,m)$，${U_i}$对${M_j}$的评分为${r_{i,j}}$，基于物品的协同过滤算法主要分为两步：

 A.	对于目标用户${U_i}$及其待评分的物品${M_j}$，根据用户对物品的历史偏好数据，计算物品${M_j}$与其他已评分物品之间的相似度${\rm{Sim}}(j,i)$，找到与物品Mj相似度的物品合集${N(u)}$；
 B.	根据所有物品${N(u)}$的评分情况，选出${N(u)}$中目标用户${U_i}$可能喜欢的且没有观看过的推荐给目标用户并预测评分。
$${\rm{Sim}}(j,i) = \frac{{{\sum _{u \in {U_{}}}}({M_{u,i}} - \overline {{M_u}} )({M_{u,j}} - \overline {{M_u}} )}}{{\sqrt {{\sum _{u \in {U_{}}}}{{({M_{u,i}} - \overline {{M_u}} )}^2}} \sqrt {{\sum _{u \in {U_{}}}}{{({M_{u,j}} - \overline {{M_u}} )}^2}} }}$$
式中，${M_{u,i}}$为用户${u}$对物品${i}$的评分，$\overline {{M_u}}$是用户${u}$对他买过的物品的平均打分。
	ItemCF通过下面的公式来计算用户对物品的喜好程度：
$${r_{uj}} = \frac{{\sum\limits_{j \in N(u)}^{} {Sim(j,i){r_{ui}}} }}{{\sum\limits_{j \in N(u)}^{} {Sim(j,i)} }}$$
式中，${r_{uj}}$表示用户${u}$对物品${j}$的喜好程度，物品${i}$是用户买过的物品，${r_{ui}}$表示用户${u}$对物品${i}$的偏好程度，然后根据${r_{uj}}$来对候选物品进行排序，为用户推荐分值最高的物品。

 - **算法流程**
算法输入：用户行为日志，基于协同的物品相似性矩阵
算法输出：初始推荐结果
A.	访问用户行为日志，获取该用户最近浏览过物品的用户集合U。
B.	针对集合${U}$中每个用户${u}$：
a)	访问用户相似矩阵，获取与用户相似的用户合集${N(u)}$。
b)	访问物品相似矩阵，获取与M(u)相似的物品合集${N(u)}$。
c)	针对物品合集${M(u_i)}$中的每个物品，计算用户偏好值。
d)	根据用户偏好值，对${N(u)}$的物品进行排序。
e)	取Top-N个物品，为每个物品赋予解释。
f)	保存Top-N个物品到初始推荐列表中。

 - **适用性**
 适用于物品数明显小于用户数的场合；
长尾物品丰富，用户个性化需求强烈的领域。

3.**UserCF和ItemCF的比较**
---|UserCF	|ItemCF
---|---|---
性能|适用于用户较少的场合，如果用户很多，计算用户相似度矩阵代价很大	|适用于物品数明显小于用户数的场合，如果物品很多（网页），计算物品相似度矩阵代价很大
领域|时效性较强，用户个性化兴趣不太明显的领域|长尾物品丰富，用户个性化需求强烈的领域
实时性	|用户有新行为，不一定造成推荐结果的立即变化|用户有新行为，一定会导致推荐结果的实时变化	
冷启动	|在新用户对很少的物品产生行为后，不能立即对他进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的；新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给和对它产生行为的用户兴趣相似的其他用户|新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品；但没有办法在不离线更新物品相似度表的情况下将新物品推荐给用户
推荐理由|	很难提供令用户信服的推荐解释|利用用户的历史行为给用户做推荐解释，可以令用户比较信服
###3.1.2 **基于模型的协同过滤算法**
1. **基于隐因子模型的推荐算法**
 
>**隐语义模型**是最近几年推荐系统领域最为热门的研究话题，它的核心思想是通过**隐含特征(latent factor)**联系用户兴趣和物品。也就是，对于某个用户，首先找到他的兴趣分类，然后从分类中挑选他可能喜欢的物品。

 - **基本算法**

 基于兴趣分类的方法大概需要解决3个问题：
A.	如何给物品进行分类？
B.	如何确定用户对哪些类的物品感兴趣，以及感兴趣的程度？
C.	对于一个给定的类，选择哪些属于这个类的物品推荐给用户，以及如何确定这些物品在一个类中的权重？
隐含语义分析技术采取基于用户行为统计的自动聚类，可以自动解决物品分类问题。LFM通过如下公式计算用户${u}$对物品${i}$的兴趣：
$${\rm{Preference(}}u,i{\rm{)}} = {r_{ui}} = p_u^T{q_i} = \sum\limits_{f = 1}^F {{p_{u,k}}{q_{i,k}}}$$
这个公式中，${p_{u,k}}$和${q_{i,k}}$是模型的参数，其中， 度量了用户${u}$的兴趣和第${k}$个隐类的关系，而 度量了第${k}$个隐类和物品${i}$之间的关系。要计算这两个参数，需要一个训练集，对于每个用户${u}$，训练集里都包含了用户${u}$喜欢的物品和不感兴趣的物品，通过学习这个数据集，就可以获得上面的模型参数。

 - **LFM和基于邻域的方法的比较**

  - **理论基础**  
 LFM具有比较好的理论基础，它是一种学习方法，通过优化一个设定的指标建立最优的模型。基于邻域的方法更多的是一种基于统计的方法，并没有学习过程。
  - **离线计算的空间复杂度**  
基于邻域的方法需要维护一张离线的相关表。在离线计算相关表的过程中，如果用户/物品数很多，将会占据很大的内存。而LFM在建模过程中，可以很好地节省离线计算的内存。
  - **离线计算的时间复杂度**  
 在一般情况下，LFM的时间复杂度要稍微高于UserCF和ItemCF，这主要是因为该算法需要多次迭代。但总体上，这两种算法在时间复杂度上没有质的差别。
  - **在线实时推荐**  
UserCF和ItemCF在线服务算法需要将相关表缓存在内存中，然后可以在线进行实时的预测。LFM在给用户生成推荐列表时，需要计算用户对所有物品的兴趣权重，然后排名，不太适合用于物品数非常庞大的系统，如果要用，我们也需要一个比较快的算法给用户先计算一个比较小的候选列表，然后再用LFM重新排名。另一方面，LFM在生成一个用户推荐列表时速度太慢，因此不能在线实时计算，而需要离线将所有用户的推荐结果事先计算好存储在数据库中。因此，LFM不能进行在线实时推荐，也就是说，当用户有了新的行为后，他的推荐列表不会发生变化。
  - **推荐解释**  
ItemCF算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果。但LFM无法提供这样的解释，它计算出的隐类虽然在语义上确实代表了一类兴趣和物品，却很难用自然语言描述并生成解释展现给用户。

---
2.**基于朴素贝叶斯分离的推荐算法**

 - **算法原理**
>由于推荐问题可以看成分类问题，因此可以使用机器学习领域中的分类算法加以解决。朴素贝叶斯分类算法是贝叶斯分类算法中比较简单的一种，它的基本思想是：对于给出的待分类物品和既定的类别，计算该物品在各个类别中出现的频率，哪个类别计算出的概率大就将物品归于那个类。在推荐系统中，朴素贝叶斯分类能够在已知某些评分的情况下，通过计算概率预测未知评分。

 计算中用到贝叶斯定理：
$$P(B|A) = \frac{{P(A|B)P(B)}}{{P(A)}}$$
式中，表示事件B已经发生的前提下事件A发生的概率；P(A)和P(B)均为无条件概率。

 - **算法流程**
算法输入：已知目标用户对物品${V_x}$之外的物品的评分情况，以及其他用户对各物品的评分情况。
算法输出：确定目标用户对物品${V_x}$的评分${r_{{V_x}}}$ 。

 A.	设${r_{{V_x}}} = \{ {a_1},{a_2},...,{a_m}\} $为一个待分类项，${a_1},{a_2},...,{a_m}$为${r_{{V_x}}}$的特征属性；
B.	设类别集合$C = \{ {y_1},{y_2},...,{y_n}\} $；
C.	计算$P({y_1}|{r_{{V_x}}}),P({y_2}|{r_{{V_x}}}),...,P({y_n}|{r_{{V_x}}})$：
a)	找到一个已知分类的待分类项集合作为训练样本；
b)	统计得到在各个类别下各个特征属性的条件概率估计，即
 $$\begin{array}{l}
P({a_1}|{y_1}),P({a_2}|{y_1}),...,P({a_m}|{y_1})\\
P({a_1}|{y_2}),P({a_2}|{y_2}),...,P({a_m}|{y_2})\\
\begin{array}{*{20}{c}}
{\begin{array}{*{20}{c}}
{\begin{array}{*{20}{c}}
{}&{}
\end{array}}&{}&{\begin{array}{*{20}{c}}
{}&{}
\end{array}}&{...}
\end{array}}&{}&{}&{}
\end{array}\\
P({a_1}|{y_n}),P({a_2}|{y_n}),...,P({a_m}|{y_n})
\end{array}$$
c)	如果各个特征属性是条件独立的，则根据贝叶斯定理有如下关系：
 $$P({y_1}|x){\rm{ = }}\frac{{P(x|{y_1}) \times P({y_1})}}{{P(x)}}$$
因为分母对所有类别为常数，因此只需将分子最大化即可，又由于各特征属性是条件独立的，所以有：
$$P(x|{y_i})P({y_i}) = P({a_1}|{y_i})P({a_2}|{y_i})...P({a_m}|{y_i})P({y_i}) = P({y_i})\prod\limits_{j = 1}^m {P({a_j}|{y_i})} $$
D.	如果$P({y_k}|{r_{{V_x}}}) = \max \{ P({y_1}|{r_{{V_x}}}),P({y_2}|{r_{{V_x}}}),...P({y_n}|{r_{{V_x}}})\} $，则${r_{{V_x}}} \in {y_k}$。

 - **适用性**
朴素贝叶斯分类实现起来比较简单，准确率高，但是分类的时候需要学习全部样本的信息。因此，朴素贝叶斯分类适用于数据量不大，类别较少的分类问题。

---

##3.2	**基于内容(CB)的推荐算法**
###3.2.1 **基础CB推荐算法**
 - **算法背景**
>基础CB推荐算法利用物品的基本信息和用户偏好内容的相似性进行物品推荐。通过分析用户已经浏览过的物品内容，生成用户的偏好内容，然后推荐与用户感兴趣的物品内容相似度高的其他物品。

 比如，用户近期浏览过冯小刚导演的电影“非诚勿扰”，主演是葛优；那么如果用户没有看过“私人订制”，则可以推荐给用户。因为这两部电影的导演都是冯小刚，主演都有葛优。
计算公式为：
$${\rm{Sim}}({u_i},{q_j}) = \sum\limits_k^{} {{\lambda _k}} {\rm{Sim}}({u_{ik}},{q_{jk}})$$
式中，${u_i}$表示用户，${q_j}$表示物品，${u_{ik}}$表示用户在第${k}$个方面的特征，${q_{jk}}$表示物品在第${k}$个方面的特征，${\rm{Sim}}({u_{ik}},{q_{jk}})$表示${u_i}$和${q_j}$在第${k}$个特征方面上的相似度，${\lambda _k}$表示权重。

 - **算法流程**
算法输入：物品信息，用户行为日志。
算法输出：初始推荐结果。
A. 物品表示：每个物品使用特征向量$\overrightarrow m  = ({m_1},{m_2},...{m_p})$表示，其中${m_i}$表示物品的特征属性；
B. 从用户行为日志中，获取该用户所浏览、收藏、评价、分享的物品集合M，根据物品集合M中物品的特征数据，可以学到用户的内容偏好；
C. 保存Top-K个物品到初始推荐结果中。

 - **适用场景**
适用于基础CB架构的搭建，尤其是对新上线物品会马上被推荐非常有效，被推荐的机会与老的物品是相同的。
###3.2.2 **基于TF-IDF的CB推荐算法**
 - **算法背景**
>在推荐系统中，用户的反馈往往分为两类：评分和文字评论。前者通过分数直接反映用户对物品的喜好程度，后者则需要从文字当中提取关键信息，这时需要用到**TF-IDF（Term Frequency-Inverse Document Frequency）**。TF-IDF算法被公认为信息检索中最重要的发明，在搜索、文献分类和其他相关领域有广泛应用。

 TF-IDF是自然语言处理领域中计算文档中词或短语的权值的方法，是词频（Term Frequency, TF）和逆转文档频率（Inverse Document Frequency, IDF）的乘积。TF指的是某一个给定的词语在该文件中出现的次数，这个数字通常会被正规化，以防止它偏向长的文件（同一个词语在长文件里可能会比段文件有更高的词频，而不管该词语重要与否）。IDF是一个词语普遍重要性的度量，某一特定词语的IDF，可以由总文件数目除以包含该词语的文件数目，再将得到的商取对数得到。
 - **算法原理**
TF-IDF算法基于这样一个假设：若一个词语在目标文档中出现的频率高而在其他文档中出现的频率低，那么这个词语就可以用来区分出目标文档。这个假设的主要信息有两点：

 *** 在本文档出现的频率高；
 
 *** 在其他文档出现的频率低。

 因此，TF-IDF算法的计算可以分为词频（TF）和逆转文档频率（IDF）两部分，由TF和IDF的乘积来设置文档词语的权重。
假设文档集包含的文档数为N，文档集中包含关键词${k_i}$的文档数为${n_i}$，${f_{ij}}$表示关键词${k_i}$在文档${d_j}$中出现的次数，${f_{dj}}$表示文档${d_j}$中出现的词语总数，${k_i}$在文档dj中的词频${\rm{T}}{{\rm{F}}_{ij}}$定义为
$${\rm{T}}{{\rm{F}}_{ij}} = \frac{{{f_{ij}}}}{{{f_{dj}}}}$$
这个数字通常会被正规化，以防止它偏向长的文件。
IDF衡量词语的普遍重要性。$\frac{{{n_i}}}{N}$表示某一词语在整个文档中出现的频率，由它计算的结果取对数得到关键词${k_i}$的逆文档频率${\rm{ID}}{{\rm{F}}_i}$。
$${\rm{ID}}{{\rm{F}}_i} = \log \frac{N}{{{n_i}}}$$
由TF和IDF计算词语的权重为
$${w_{ij}}{\rm{ = T}}{{\rm{F}}_{ij}} \cdot {\rm{ID}}{{\rm{F}}_i} = \frac{{{f_{ij}}}}{{{f_{dj}}}} \cdot \log \frac{N}{{{n_i}}}$$
可以看出，TF-IDF与词语在文档中的出现次数成正比，与该词在整个文档集中的出现次数成反比。在目标文档中，提取关键词的方法就是将该文档所有词语的TF-IDF计算出来并进行对比，取其中TF-IDF值最大的${k}$个数组成目标文档的特征向量来表示该文档。
###3.2.3 **基于KNN的CB推荐算法**
 - **算法背景**
>**KNN(k-Nearest Neighbor)**算法基于这样的假设：如果在特征空间中，一个样本的k个最邻近样本中的大多数样本属于某一个类别，则该样本也属于这个类别。

 - **算法原理**

 KNN在CB推荐算法中的应用于在CF推荐算法中的应用极为相似，它们都是要首先找到与目标物品相似的且已经被用户${u}$评价过的${k}$个物品，然后根据用户户${u}$对这${k}$个物品的评价来预测其目标物品的评价。它们的差别在于，CF推荐算法中的KNN是根据用户对物品的评分来计算物品间相似度的，而CB推荐算法中KNN是根据物品画像来计算相似度的，所以对于后者来说，如何通过物品画像来计算物品间的相似度是算法中的关键步骤。相似度的计算可以使用余弦相似度或Pearson相关系数的计算方法。KNN算法流程如下：
 
 算法输入：用户已评分物品，目标物品${i}$。
算法输出：用户对目标物品${i}$的评分。

 A. 采用余弦相似度公式计算相似度。
B. 选择最近邻。在用户${u}$评过分的所有物品中，找出${k}$个与目标物品${i}$相似度最高的物品，并用${N(u,i)}$来表示这出${k}$个物品的集合。
C. 计算预测值。在第二步的基础上，可使用以下公式计算用户对目标物品的评分：
$${\widehat r_{u,i}} = \frac{{\sum\limits_{n \in N(u,i)}^{} {{S_{i,n}}{r_{u,n}}} }}{{\sum\limits_{n \in N(u,i)}^{} {{S_{i,n}}} }}$$
式中，${\widehat r_{u,i}} $表示用户${u}$对物品${i}$的预测评分，${S_{i,n}}$是相似度。
###3.2.4 **基于Rocchio的CB推荐算法**
 - **算法背景**
>Rocchio是从用户浏览历史中抽取用户喜好的物品特征来构建用户画像的一种常用算法，是信息检索领域处理**相关反馈（Relevance Feedback）**的一个著名算法。它提供了如何通过用户浏览的物品，反馈计算用户特征向量中属性值的方法。

 举个简单例子，假如用户观看过“星球大战”和“加勒比海盗”，并给予高分，那么根据用户的行为历史数据构建画像时，用户的特征向量可表示为{“动作”：1，“欧美”：1，“科幻”：1，“冒险”：0.5}。
 - **算法原理**
Rocchio算法基于这样的假设：如果我们需要计算出最精准度的用户特征向量${U_c}$，那么这个用户特征向量应该与用户喜欢的物品特征最相似，与用户讨厌的物品特征最不同。若${V_1}$表示用户喜欢的物品，${V_h}$表示用户讨厌的物品，那么根据Rocchio算法的思想，定义最优的用户特征向量为：
$${U_{opt}} = \arg \max [{\rm{Sim}}({U_c},{V_1}){\rm{ - Sim}}({U_c},{V_h})]$$
式中，${\rm{Sim}}({U_c},{V_1})$表示用户特征向量与用户喜欢的物品的相似度，采用余弦相似度计算，公式为：
$${U_{opt}} = \frac{1}{{\left| {{V_1}} \right|}}\sum\limits_{{{\overrightarrow w }_j} \in {V_1}}^{} {{{\overrightarrow w }_j}}  - \frac{1}{{\left| {{V_h}} \right|}}\sum\limits_{{{\overrightarrow w }_j} \in {V_h}}^{} {{{\overrightarrow w }_j}} $$
更新用户的特征向量，修改公式为：
$${U_{opt}} = \alpha {U_0} + \beta \frac{1}{{\left| {{V_1}} \right|}}\sum\limits_{{{\overrightarrow w }_j} \in {V_1}}^{} {{{\overrightarrow w }_j}}  - \gamma \frac{1}{{\left| {{V_h}} \right|}}\sum\limits_{{{\overrightarrow w }_j} \in {V_h}}^{} {{{\overrightarrow w }_j}} $$
式中，${U_0}$是原始的用户特征向量，${\alpha}$、${\beta}$、${\gamma}$ 为权重。若用户新的历史数据较多，那么可以增大${\beta}$和${\gamma}$  的值，反之，用户更新数据较少则可以适当减小${\beta}$和${\gamma}$ 的值。在基于内容的物品推荐中，根据用户的历史行为数据建立用户画像，我们可以采用Rocchio算法不断地调整用户的特征向量${U_c}$。
###3.2.5 **基于决策树的CB推荐算法**

 - **算法背景**
>基于决策树的推荐算法在训练阶段会生成一个显示的决策模型。决策树可以通过训练数据构建并有效判断一个新的物品是否可能受到欢迎。当物品的特征属性较少时，采用决策树算法能够取得不错的效果，另外，决策树学习的思想也比较容易被理解，在物品推荐时的可解释性较好。

 - **算法原理**

 在物品推荐系统中，决策树的内部节点通常表示物品的特征属性，这些节点用于区分物品集合，例如，通过物品中是否包含这个特征将其进行分类。在只有两个分类的简单数据集中，用户是否对物品感兴趣一般出现在决策树的叶子节点上。
<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/eqnfzltlqcada2iqr6813hbm/image_1bc7pjcno4mml108min461msk6i.png" width="400" height="400" alt="Item-based filtering" /></div>

###3.2.6 **基于线性分类的CB推荐算法**
 - **算法背景**
>将基于内容的物品推荐问题视为分类问题时，可以采用多种机器学习方法。从一个更抽象的角度上看，大部分学习方法致力于找到一个可以准确区分用户喜欢和不喜欢的物品的线性分类模型系数。

 将物品数据用n维特征向量来表示，线性分类器试图在给定的物品特征空间中找到一个能够将物品正确分类的平面，一类点尽可能在平面的某一边（喜欢），另一类在平面的另一边（不喜欢）。
 - **算法原理**

 基于线性分类器的CB推荐算法通过物品特征的线性组合进行分类。若输入的物品特征向量为$\overrightarrow v  = ({v_1},{v_2},...{v_n})$，输出的结果${y}$表示用户是否喜欢物品，则线性分类器可以表示为：
$$y = {\overrightarrow w ^T} \cdot \overrightarrow v  = \sum\limits_{i = 1}^n {\overrightarrow {{w_i}} } \overrightarrow {{v_i}} $$
式中，$\overrightarrow {{w_i}} $表示物品特征向量对应的权重，根据输入的物品特征属性做出决定输出结果。
###3.2.7 **基于朴素贝叶斯的CB推荐算法**
 - **算法背景**
>基于朴素贝叶斯的推荐系统假设用户和物品的特征向量中的各个分量之间条件独立，判断用户是否对某个物品有兴趣的方法是将这个问题转化为分类问题：喜欢和不喜欢。

 计算物品分类情况的后验概率为：
$$P(C|v) = \frac{{(\prod\limits_{i = 1}^n {P({v_i}|C)} ) \times P(C)}}{{P(v)}}$$
式中，${v_i}(i = 1,2,...,n)$表示物品的相关属性；${C}$为物品的分类,$P({v_i}|C = c)$表示在分类${c}$的一个物品的特征属性${v_i}$出现的概率。这样，物品分类的后验概率可以通过观察分析训练数据得到。

 - **算法原理**

 推荐系统中，分类${c}$下的一个物品特征属性${v_i}$的条件概率用${v_i}$ 在分类${c}$下所有物品中出现的频率近似表示，即
$$P({v_i}|C){\rm{ = }}\frac{{{\rm{CountTerms(}}{{\rm{v}}_i}{\rm{,item(c))}}}}{{{\rm{Allterms}}({\rm{item}}(c))}}$$
式中，${\rm{CountTerms(}}{{\rm{v}}_i}{\rm{,item(c))}}$表示 在标记为${c}$的物品出现的次数，${\rm{Allterms}}({\rm{item}}(c))$表示在这些物品中出现的所有特征属性的个数。为了预防计算概率为0的情况，对式子进行平滑，新公式如下：
$$\hat P({v_i}|C){\rm{ = }}\frac{{{\rm{CountTerms(}}{{\rm{v}}_i}{\rm{,item(c)) + 1}}}}{{{\rm{Allterms}}({\rm{item}}(c)){\rm{ + }}\left| V \right|}}$$
式中,$\left| V \right|$表示所有物品中的出现的不同特征属性数。
##3.3	**基于知识的推荐算法**
###3.3.1 **概述**
>**基于知识（Knowledge-based, KB）**的推荐算法,是区别于基于CB和基于CF的常见推荐方法。如果说CB和CF像通用搜索引擎的话，KB好比某个领域的垂直搜索引擎，可以提供该领域的特殊需求，包括专业性的优质特征，帮助提高搜索引擎在特定领域的服务。

 以视频推荐为例，一部电影的上映时期和档期热度，哪些导演执导的一定是大片，变形金刚和指环王系列口碑肯定不会太差，都是非常有价值的推荐信息。此外，基于知识的推荐，也更容易满足主观个性化需求。例如，对于VIP用户，如果配置好了偏好，就可以为其提供更加精准的推荐服务。
###3.3.2 **约束知识与约束推荐算法**
  如今网上购物所能涵盖的物品越来越丰富，人们逐渐发现推荐系统的CF和CB推荐算法并不能很好地适应某些特殊物品的推荐需求。例如，更新换代非常快的而人们又通常不会经常更换的电子产品。对于这些产品来说，其各方面的性能参数在几年间就会有很大变化，代表历史偏好的用户画像并不能很好地反映用户当前的购买需求，于是就需要推荐系统将用户当前的需求作为重要信息参考源。人们发现可以利用物品的参数特征等属性形成约束知识，再将用户对物品的特定刻画为约束条件，然后经过对物品集合的约束满足问题的求解，就可以得到用户所期望的物品了。

 - **创建推荐任务**
推荐任务是以元组${（R,I）}$的形式表示出来，其中用集合${R}$表示目标用户对物品的特定需求，即对物品的约束条件，用集合${I}$表示一个物品集合。推荐的任务就是从集合${I}$中确定出能够满足集合${R}$要求的物品。

 - **推荐任务的解决**
推荐任务的解决是以找到可能的集合${S}$为目标，集合${S}$应满足的条件是$S \subseteq I$，并且$\forall {I_i} \in S:{I_i} \in {\sigma _{(R)}}I$，其中，${\sigma }$表示对集合${I}$进行合取查询的运算符，R表示对物品的约束条件或选择标准。

 - **冲突集**
冲突集CS应满足的条件为：$CS \subseteq R$，并且${\sigma _{(CS)}}I = \emptyset $。特别地，当不存在集合$CS' \subset CS$时，集合CS被称为最小冲突集。

 - **诊断集**
诊断集$\Delta $应满足的条件是$\Delta  \subseteq R$，并且${\sigma _{(CS)}}I \ne \emptyset $。特别地，当不存在集合$\Delta' \subset \Delta$时，集合${\Delta}$被称为最小诊断集。
###3.3.3 **关联知识与关联推荐算法**
>**关联知识**以关联规则为表现形式，用以描述数据库中数据之间关联性的知识。在推荐系统领域，可以通过对用户画像中关联规则的挖掘分析来分析用户的习惯，发现物品之间的关联性，并利用这种关联性指导系统做出推荐。

 - **算法输入**：n个用户画像。

 - **算法输出**：针对目标用户u的Top-N推荐列表。
 
 1. 从系统中的n个用户画像中挖掘出所有的强关联规则，建立集合${P_u}$以表示目标用户u尚未观看但极有可能感兴趣的物品。
 2. 再次使用置信度对集合${P_u}$中的物品进行高低排序。
 3. 取出排序列表中的前N个物品构成Top-N推荐列表。 由于对系统中全体用户的画像进行规则关联挖掘意义不明显且计算量大，所以基于关联规则的推荐算法常与CF推荐算法混合使用。在这类混合方案中，使用了CF推荐算法中的最近邻算法将用户画像数目n限定在目标用户的最邻近范围内，使得关联规则挖掘算法处理的数据规模被有针对性地限定在一定范围内。

##3.4	**混合推荐算法**
>各种推荐方法都有优缺点，为了扬长补短，在实际中常常采用**混合推荐（Hybrid Recommendation）**。研究和应用最多的是内容推荐和协同过滤推荐的组合。最简单的做法就是分别用基于内容的方法和协同过滤推荐方法去产生一个推荐预测结果，然后用某方法组合其结果。尽管从理论上有很多种推荐组合方法，但在某一具体问题中并不见得都有效，组合推荐一个最重要原则就是通过组合后要能避免或弥补各自推荐技术的弱点。

 - **加权式**：加权多种推荐技术结果。
<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/9q8trfb0eetc6fh0x5z7covb/%E5%8A%A0%E6%9D%83%E5%BC%8F.png" width="800" height="400" alt="Item-based filtering" /></div>

---

 - **切换式**：根据问题背景和实际情况或要求决定变换采用不同的推荐技术。
<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/ao6dt4qo7v88qo9kq05iod7d/%E5%88%87%E6%8D%A2%E5%BC%8F.png" width="800" height="400" alt="Item-based filtering" /></div>

---

 - **混杂式**：同时采用多种推荐技术给出多种推荐结果为用户提供参考。
<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/kishlf79bas26r1xamjcqd00/%E6%B7%B7%E6%9D%82%E5%BC%8F.png" width="800" height="400" alt="Item-based filtering" /></div>

---

 - **特征组合**：组合来自不同推荐数据源的特征被另一种推荐算法所采用。
<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/5bwaztuxoojdpeom5tmzusy3/%E7%89%B9%E5%BE%81%E7%BB%84%E5%90%88.png" width="800" height="400" alt="Item-based filtering" /></div>

---

 - **层叠式**：先用一种推荐技术产生一种粗糙的推荐结果，第二种推荐技术在此推荐结果的基础上进一步作出更精确的推荐。
<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/90jsrm86u5rkblj18j85ycxb/%E5%B1%82%E5%8F%A0%E5%BC%8F.png" width="800" height="400" alt="Scoring" /></div>

---

  - **特征补充**：一种技术产生附加的特征信息嵌入到另一种推荐技术的特征输入中。

<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/5cjy4oh25xxdgbb3sgozphfs/%E7%89%B9%E5%BE%81%E8%A1%A5%E5%85%85.png" width="800" height="400" alt="Scoring" /></div>
---

   - **级联式**：用一种推荐方法产生的模型作为另一种推荐方法的输入。
<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/6zdr0qwgt45myq77ifuuvat9/%E7%BA%A7%E8%81%94%E5%BC%8F.png" width="800" height="400" alt="Scoring" /></div>

---

#4. **推荐系统的评估（Evaluation）**

<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/o1opib5c0ity4ueoj66q9xjg/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E8%AF%84%E6%B5%8B.png" width="300" height="300" alt="Scoring" /></div>

>如何判断推荐系统的优劣？这是推荐系统评测需要解决的首要问题。一个完整的推荐系统一般存在3个参与方：用户、物品提供者和提供推荐系统的网站。

好的推荐系统设计，能够让推荐系统本身收集到高质量的用户反馈，不断完善推荐的质量，增加用户和网站的交互，提高网站的收入。因此在评测一个推荐算法时，需要同时考虑三方的利益，一个好的推荐系统是能够令三方共赢的系统。
## 4.1 **推荐系统实验方法**

>一般来说，一个新的推荐算法最终上线，需要完成上面所说的3个实验：离线实验、用户调查和在线实验。

###4.1.1 **离线实验**
离线实验的方法一般由如下几个步骤构成：

 - 通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集；
 - 将数据集按照一定的规则分成训练集和测试集；
 - 在训练集上训练用户兴趣模型，在测试集上进行预测；
 - 通过事先定义的离线指标评测算法在测试集上的预测结果。

从上面的步骤可以看到，推荐系统的离线实验都是在数据集上完成的，也就是说它不需要一个实际的系统来供它实验，而只要有一个从实际系统日志中提取的数据集即可，因此**离线实验速度快，可以测试大量算法，这是离线实验的显著优点**。而它的主要**缺点是无法获得很多商业上关注的指标**，如点击率、转化率等，而找到和商业指标非常相关的离线指标也是很困难的事情。

###4.1.2 **用户调查**
离线实验的指标和实际的商业指标存在差距，比如预测准确率和用户满意度之间就存在很大差别，高预测准确率不等于高用户满意度。因此，如果要准确评测一个算法，需要相对比较真实的环境。最好的方法就是将算法直接上线测试，但在对算法会不会降低用户满意度不太有把握的情况下，上线测试具有较高的风险，所以在**上线测试前一般需要做一次称为用户调查的测试**。

**测试用户的选择必须尽量保证测试用户的分布和真实用户的分布相同**，比如男女各半，以及年龄、活跃度的分布都和真实用户分布尽量相同。此外，用户调查要尽量保证是双盲实验，不要让实验人员和用户事先知道测试的目标，以免用户的回答和实验人员的测试受主观成分的影响。

用户调查的优缺点也很明显。它的**优点是可以获得很多体现用户主观感受的指标**，相对在线实验风险很低，出现错误后很容易弥补。**缺点是招募测试用户代价较大，很难组织大规模的测试用户**，因此会使测试结果的统计意义不足。此外，在很多时候设计双盲实验非常困难，而且用户在测试环境下的行为和真实环境下的行为可能有所不同，因而在测试环境下收集的测试指标可能在真实环境下无法重现。
###4.1.3 **在线实验**

<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/4scueptos7p8zffspe5rdsjo/ABtest.png" width="500" height="500" alt="Scoring" /></div>
在完成离线实验和必要的用户调查后，可以将推荐系统上线做AB测试，将它和旧的算法进行比较。**AB测试是一种很常用的在线评测算法的实验方法**。它通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后通过统计不同组用户的各种不同的评测指标比较不同算法，比如可以统计不同组用户的点击率，通过点击率比较不同算法的性能。对AB测试感兴趣的读者可以浏览一下网站http://www.abtests.com/，该网站给出了很多通过实际AB测试提高网站用户满意度的例子，从中我们可以学习到如何进行合理的AB测试。

AB测试的**优点是可以公平获得不同算法实际在线时的性能指标**，包括商业上关注的指标。AB测试的**缺点主要是周期比较长**，必须进行长期的实验才能得到可靠的结果。因此一般不会用AB测试测试所有的算法，而只是用它测试那些在离线实验和用户调查中表现很好的算法。其次，一个大型网站的AB测试系统的设计也是一项复杂的工程。一个大型网站的架构分前端和后端，从前端展示给用户的界面到最后端的算法，中间往往经过了很多层，这些层往往由不同的团队控制，而且都有可能做AB测试。如果为不同的层分别设计AB测试系统，那么不同的AB测试之间往往会互相干扰。比如，当我们进行一个后台推荐算法的AB测试，同时网页团队在做推荐页面的界面AB测试，最终的结果就是你不知道测试结果是自己算法的改变，还是推荐界面的改变造成的。因此，切分流量是AB测试中的关键，不同的层以及控制这些层的团队需要从一个统一的地方获得自己AB测试的流量，而不同层之间的流量应该是正交的。
## 4.2 **评测指标**
### 4.2.1 **用户满意度**
>用户作为推荐系统的重要参与者，其**满意度是评测推荐系统的最重要指标**。但是，用户满意度没有办法离线计算，只能通过用户调查或者在线实验获得。
<div  align="center"> <img src="http://static.zybuluo.com/Jessy923/ezdyla4fxtdstzedh8gcqz04/Douban.png" width="600" height="400" alt="Scoring" /></div>
在线系统中，用户满意度主要通过一些对用户行为的统计得到。比如在电子商务网站中，用户如果购买了推荐的商品，就表示他们在一定程度上满意。因此，我们可以利用购买率度量用户的满意度。此外，有些网站会通过设计一些用户反馈界面收集用户满意度。比如在豆瓣网络电台中，都有对推荐结果满意或者不满意的反馈按钮（通过红心和垃圾箱的反馈来度量用户满意度），通过统计两种按钮的单击情况就可以度量系统的用户满意度。更一般的情况下，我们可以用点击率、用户停留时间和转化率等指标度量用户的满意度。

---

### 4.2.2 **预测准确度**
>**预测准确度衡量一个推荐系统或者推荐算法预测用户行为的能力，是最重要的推荐系统离线评测指标**。从推荐系统诞生的那一天起，几乎99%与推荐相关的论文都在讨论这个指标。这主要是因为该指标可以通过离线实验计算，方便了很多学术界的研究人员研究推荐算法。

在计算该指标时需要有一个离线的数据集，该数据集包含用户的历史行为记录。然后，将该数据集通过时间分成训练集和测试集。最后，通过在训练集上建立用户的行为和兴趣模型预测用户在测试集上的行为，并计算预测行为和测试集上实际行为的重合度作为预测准确度。预测准确度的指标包括以下几类：

 - **评分预测**
 很多提供推荐服务的网站都有一个让用户给物品打分的功能。如果知道了用户对物品的历史评分，就可以从中习得用户的兴趣模型，并预测该用户在将来看到一个他没有评过分的物品时，会给这个物品评多少分。

---

 - **TopN推荐**
网站在提供推荐服务时，一般是给用户一个个性化的推荐列表，这种推荐叫做TopN推荐。TopN推荐的预测准确率一般通过准确率（precision）/召回率（recall）度量。令${R(u)}$是根据用户在训练集上的行为给用户作出的推荐列表，而${T(u)}$是用户在测试集上的行为列表。那么，推荐结果的召回率定义为：
$${\rm{Recall}} = \frac{{\sum\limits_{u \in U}^{} {\left| {R(u) \cap T(u)} \right|} }}{{\sum\limits_{u \in U}^{} {\left| {T(u)} \right|} }}$$
推荐结果的精准率定义为：
$${\rm{Precision}} = \frac{{\sum\limits_{u \in U}^{} {\left| {R(u) \cap T(u)} \right|} }}{{\sum\limits_{u \in U}^{} {\left| {R(u)} \right|} }}$$

---

 - **覆盖率**
覆盖率**（coverage）描述一个推荐系统对物品长尾的发掘能力**。覆盖率有不同的定义方法，最简单的定义为推荐系统能够推荐出来的物品占总物品集合的比例。假设系统的用户集合为${U}$，推荐系统给每个用户推荐一个长度为N的物品列表${R(u)}$。那么推荐系统的覆盖率可以通过下面的公式计算：
$${\rm{Coverage = }}\frac{{\left| {{ \cup _{u \in U}}R(u)} \right|}}{{\left| I \right|}}$$
**覆盖率是一个内容提供商会关心的指标**。以图书推荐为例，出版社可能会很关心他们的书有没有被推荐给用户。覆盖率为100%的推荐系统可以将每个物品都推荐给至少一个用户。此外，从上面的定义也可以看到，热门排行榜的推荐覆盖率是很低的，它只会推荐那些热门的物品，这些物品在总物品中占的比例很小。一个好的推荐系统不仅需要有比较高的用户满意度，也要有较高的覆盖率。


---

  - **多样性**
为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性。尽管用户的兴趣在较长的时间跨度中是一样的，但具体到用户访问推荐系统的某一刻，其兴趣往往是单一的，那么如果推荐列表只能覆盖用户的一个兴趣点，而这个兴趣点不是用户这个时刻的兴趣点，推荐列表就不会让用户满意。反之，如果推荐列表比较多样，覆盖了用户绝大多数的兴趣点，那么就会增加用户找到感兴趣物品的概率。因此给用户的推荐列表也需要满足用户广泛的兴趣，即具有多样性。
**多样性描述了推荐列表中物品两两之间的不相似性**。因此，多样性和相似性是对应的。假设$s(i,j) \in [0,1]$定义了物品${i}$和${j}$之间的相似度，那么用户${u}$的推荐列表${R(u)}$的多样性定义如下：
$${\rm{Diversity}} = 1 - \frac{{\sum\limits_{i,j \in R(u),i \ne j}^{} {s(i,j)} }}{{\frac{1}{2}\left| {R(u)} \right|(\left| {R(u)} \right| - 1)}}$$
而推荐系统的整体多样性可以定义为所有用户推荐列表多样性的平均值：
$${\rm{Diversity = }}\frac{1}{{\left| U \right|}}\sum\limits_{u \in U}^{} {{\rm{Diversity}}(R(u))} $$
 从上面的定义可以看到，不同的物品相似度度量函数${s(i,j)}$可以定义不同的多样性。如果用内容相似度描述物品间的相似度，我们就可以得到内容多样性函数，如果用协同过滤的相似度函数描述物品间的相似度，就可以得到协同过滤的多样性函数。

---

  - **新颖性**
 新颖的推荐是指给用户推荐那些他们以前没有听说过的物品。在一个网站中实现新颖性的最简单办法是，把那些用户之前在网站中对其有过行为的物品从推荐列表中过滤掉。比如在一个视频网站中，新颖的推荐不应该给用户推荐那些他们已经看过、打过分或者浏览过的视频。但是，有些视频可能是用户在别的网站看过，或者是在电视上看过，因此仅仅过滤掉本网站中用户有过行为的物品还不能完全实现新颖性。

 但是，用推荐结果的平均流行度度量新颖性比较粗略，因为不同用户不知道的东西是不同的。因此，要准确地统计新颖性需要做用户调查。

---

 - **惊喜度**
惊喜度**（serendipity）是最近这几年推荐系统领域最热门的话题**。令用户惊喜的推荐结果是和用户历史上喜欢的物品不相似，但用户却觉得满意的推荐。那么，定义惊喜度需要首先定义推荐结果和用户历史上喜欢的物品的相似度，其次需要定义用户对推荐结果的满意度。

 用户满意度只能通过问卷调查或者在线实验获得，而推荐结果和用户历史上喜欢的物品相似度一般可以用内容相似度定义。也就是说，如果获得了一个用户观看电影的历史，得到这些电影的演员和导演集合A，然后给用户推荐一个不属于集合A的导演和演员创作的电影，而用户表示非常满意，这样就实现了一个惊喜度很高的推荐。**因此提高推荐惊喜度需要提高推荐结果的用户满意度，同时降低推荐结果和用户历史兴趣的相似度**。

---

  - **信任度**
 度量推荐系统的信任度只能通过问卷调查的方式，询问用户是否信任推荐系统的推荐结果。提高推荐系统的信任度主要有两种方法：
  - 需要**增加推荐系统的透明度（transparency）**，而增加推荐系统透明度的主要办法是提供推荐解释。只有让用户了解推荐系统的运行机制，让用户认同推荐系统的运行机制，才会提高用户对推荐系统的信任度。
  - 考虑用户的社交网络信息，**利用用户的好友信息给用户做推荐**，并且用好友进行推荐解释。这是因为用户对他们的好友一般都比较信任，因此如果推荐的商品是好友购买过的，那么他们对推荐结果就会相对比较信任。


---

 - **实时性**
在很多网站中，因为物品（新闻、微博等）具有很强的时效性，所以需要在物品还具有时效性时就将它们推荐给用户。比如，给用户推荐昨天的新闻显然不如给用户推荐今天的新闻。因此，在这些网站中，推荐系统的实时性就显得至关重要。

 推荐系统的实时性包括两个方面：

  - **推荐系统需要实时地更新推荐列表来满足用户新的行为变化**。比如，当一个用户购买了iPhone，如果推荐系统能够立即给他推荐相关配件，那么肯定比第二天再给用户推荐相关配件更有价值。很多推荐系统都会在离线状态每天计算一次用户推荐列表，然后于在线期间将推荐列表展示给用户。这种设计显然是无法满足实时性的。与用户行为相应的实时性，可以通过推荐列表的变化速率来评测。如果推荐列表在用户有行为后变化不大，或者没有变化，说明推荐系统的实时性不高。
  - **推荐系统需要能够将新加入系统的物品推荐给用户**。这主要考验了推荐系统处理物品冷启动的能力。对于新物品推荐能力，我们可以利用用户推荐列表中有多大比例的物品是当天新加的来评测。

---

  - **健壮性**
 任何一个能带来利益的算法系统都会被人攻击，这方面最典型的例子就是搜索引擎。搜索引擎的作弊和反作弊斗争异常激烈，这是因为如果能让自己的商品成为热门搜索词的第一个搜索果，会带来极大的商业利益。推荐系统目前也遇到了同样的作弊问题，而**健壮性（robust,鲁棒性）**指标衡量了一个推荐系统抗击作弊的能力。

 **算法健壮性的评测主要利用模拟攻击**。首先，给定一个数据集和一个算法，可以用这个算法给这个数据集中的用户生成推荐列表。然后，用常用的攻击方法向数据集中注入噪声数据，然后利用算法在注入噪声后的数据集上再次给用户生成推荐列表。最后，通过比较攻击前后推荐列表的相似度评测算法的健壮性。如果攻击后的推荐列表相对于攻击前没有发生大的变化，就说明算法比较健壮。
 在实际系统中，提高系统的健壮性，除了选择健壮性高的算法，还有以下方法：

   - 设计推荐系统时尽量使用代价比较高的用户行为。比如，如果有用户购买行为和用户浏览行为，那么主要应该使用用户购买行为，因为购买需要付费，所以攻击购买行为的代价远远大于攻击浏览行为。
   - 在使用数据前，进行攻击检测，从而对数据进行清理。
 
---
  
 - **商业目标**
 很多时候，**网站评测推荐系统更加注重网站的商业目标是否达成**，而商业目标和网站的盈利模式是息息相关的。一般来说，最本质的商业目标就是平均一个用户给公司带来的盈利。不过这种指标不是很难计算，只是计算一次需要比较大的代价。因此，很多公司会根据自己的盈利模式设计不同的商业目标。

 **不同的网站具有不同的商业目标**。比如电子商务网站的目标可能是销售额，基于展示广告盈利的网站其商业目标可能是广告展示总数，基于点击广告盈利的网站其商业目标可能是广告点击总数。因此，设计推荐系统时需要考虑最终的商业目标，而网站使用推荐系统的目的除了满足用户发现内容的需求，也需要利用推荐系统加快实现商业上的指标。



---
#5. **推荐系统的冷启动问题（Cold Start）**

##5.1 **冷启动问题定义**
>推荐系统需要根据用户的历史行为和兴趣预测用户未来的行为和兴趣，对于BAT这类大公司来说，它们已经积累了大量的用户数据，不发愁。但是对于很多做纯粹推荐系统的网站或者很多在开始阶段就希望有个性化推荐应用的网站来说，如何在对用户一无所知（即没有用户行为数据）的情况下进行最有效的推荐呢？这就衍生了冷启动问题。

##5.2 **冷启动的分类**
冷启动问题主要分为3类：

 - **用户冷启动**，即如何给新用户做个性化推荐
 - **物品冷启动**，即如何将新的物品推荐给可能对它感兴趣的用户
 - **系统冷启动**，即如何在一个新开发的网站（没有用户，没有用户行为，只有部分物品信息）上设计个性化推荐系统，从而在网站刚发布时就让用户体会到个性化推荐
##5.3 **冷启动问题的解决方案** 

###5.3.1 **提供非个性化的推荐**
最简单的例子就是提供热门排行榜，可以给用户推荐热门排行榜，等到用户数据收集到一定的时候，再切换为个性化推荐。Netflix的研究也表明新用户在冷启动阶段确实是更倾向于热门排行榜的，老用户会更加需要长尾推荐.

###5.3.2 **利用用户注册信息**
用户的注册信息主要分为3种：

 - 人口统计学信息，包括年龄、性别、职业、民族、学历和居住地
 - 用户兴趣的描述，部分网站会让用户用文字来描述兴趣
 - 从其他网站导入的用户站外行为，比如用户利用社交网站账号登录，就可以在获得用户授权的情况下导入用户在该社交网站的部分行为数据和社交网络数据

这种个性化的粒度很粗，假设性别作为一个粒度来推荐，那么所有刚注册的女性看到的都是同样的结果，但是相对于男女不区分的方式，这种推荐精度已经大大提高了。

###5.3.3 **选择合适的物品启动用户的兴趣**
用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。一般来说，能够用来启动用户兴趣的物品需要具有以下特点：

 - 比较热门，如果要让用户对物品进行反馈，前提是用户得知道这是什么东西；
 - 具有代表性和区分性，启动用户兴趣的物品不能是大众化或老少咸宜的，因为这样的物品对用户的兴趣没有区分性；
 - 启动物品集合需要有多样性，在冷启动时，我们不知道用户的兴趣，而用户兴趣的可能性非常多，为了匹配多样的兴趣，我们需要提供具有很高覆盖率的启动物品集合，这些物品能覆盖几乎所有主流的用户兴趣
###5.3.4 **利用物品的内容信息**
物品冷启动问题在新闻网站等时效性很强的网站中非常重要，因为这些网站时时刻刻都有新物品加入，而且每个物品必须能够再第一时间展现给用户，否则经过一段时间后，物品的价值就大大降低了。

 - 对UserCF算法来说，针对推荐列表并不是给用户展示内容的唯一列表（大多网站都是这样的）的网站。当新物品加入时，总会有用户通过某些途径看到，那么当一个用户对其产生反馈后，和他历史兴趣相似的用户的推荐列表中就有可能出现该物品，从而更多的人对该物品做出反馈，导致更多的人的推荐列表中出现该物品。因此，该物品就能不断扩散开来，从而逐步展示到对它感兴趣用户的推荐列表中
针对推荐列表是用户获取信息的主要途径（例如豆瓣网络电台）的网站UserCF算法就需要解决第一推动力的问题，即第一个用户从哪儿发现新物品。最简单的方法是将新的物品随机战士给用户，但是太不个性化。因此可以考虑利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户

 - 对ItemCF算法来说，物品冷启动就是很严重的问题了。因为该算法的基础是通过用户对物品产生的行为来计算物品之间的相似度，当新物品还未展示给用户时，用户就无法产生行为。为此，只能利用物品的内容信息计算物品的相关程度。基本思路就是将物品转换成关键词向量，通过计算向量之间的相似度（例如计算余弦相似度），得到物品的相关程度。

###5.3.5 **采用专家标注**
很多系统在建立的时候，既没有用户的行为数据，也没有充足的物品内容信息来计算物品相似度。这种情况下，很多系统都利用专家进行标注。

代表系统：个性化网络电台Pandora、电影推荐网站Jinni。

以Pandora电台为例，Pandora雇用了一批音乐人对几万名歌手的歌曲进行各个维度的标注，最终选定了400多个特征。每首歌都可以标识为一个400维的向量，然后通过常见的向量相似度算法计算出歌曲的相似度。

---
#6. **推荐系统实战**

##6.1 **推荐系统学术研究常用数据集**

 1. **MovieLen**(https://grouplens.org/datasets/movielens/)
 MovieLens数据集中，用户对自己看过的电影进行评分，分值为1~5。MovieLens包括两个不同大小的库，适用于不同规模的算法。小规模的库是943个独立用户对1 682部电影作的10 000次评分的数据；大规模的库是6 040个独立用户对3 900部电影作的大约100万次评分。

 2. **BookCrossing**(http://www2.informatik.uni-freiburg.de/~cziegler/BX/)
 这个数据集是网上的Book-Crossing图书社区的278858个用户对271379本书进行的评分，包括显式和隐式的评分。这些用户的年龄等人口统计学属性(demographic feature)都以匿名的形式保存并供分析。这个数据集是由Cai-Nicolas Ziegler使用爬虫程序在2004年从Book-Crossing图书社区上采集的。

 3. **Jester Joke**(http://eigentaste.berkeley.edu/dataset/)
Jester Joke是一个网上推荐和分享笑话的网站。这个数据集有73496个用户对100个笑话作的410万次评分。评分范围是−10~10的连续实数。这些数据是由加州大学伯克利分校的Ken Goldberg公布的。

 4. **Netflix**(http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a)
这个数据集来自于电影租赁网址Netflix的数据库。Netflix于2005年底公布此数据集并设立百万美元的奖金(netflix prize)，征集能够使其推荐系统性能上升10%的推荐算法和架构。这个数据集包含了480 189个匿名用户对大约17 770部电影作的大约10亿次评分。

 5. **Usenet Newsgroups**(http://qwone.com/~jason/20Newsgroups/)
这个数据集包括20个新闻组的用户浏览数据。最新的应用是在KDD 2007上的论文。新闻组的内容和讨论的话题包括计算机技术、摩托车、篮球、政治等。用户们对这些话题进行评价和反馈。

 6. **UCI库**(https://archive.ics.uci.edu/ml/datasets.html)
UCI库是Blake等人在1998年开放的一个用于机器学习和评测的数据库，其中存储大量用于模型训练的标注样本，可用于推荐系统的性能测试数据。

---

##6.2 **推荐系统可用库**

1. **LibRec**（http://www.librec.net）
 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/fveol4xabwxgneniw55ly7kt/Librec.png" width="800" height="400" alt="Librec Context" /></div>

 LibRec是一个覆盖了70余个各类型推荐算法的推荐系统开源算法库，有效地解决了评分预测和物品推荐两大关键的推荐问题。该项目结构清晰、代码风格良好、测试充分、注释与手册完善，基于GPL3.0协议代码开源。GitHub链接为 https://github.com/guoguibing/librec



2. **Crab**（http://muricoca.github.io/crab/tutorial.html）
 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/wl8yryo5fpki7vnow6r1eewt/Crab.png" width="800" height="400" alt="Librec Context" /></div>

 Crab是基于Python开发的开源推荐软件，其中实现有item和user的协同过滤。据说更多算法还在开发中，Crab的python代码看上去很清晰明了，适合一读。

 系统的Tutorial可以看这里：
http://muricoca.github.io/crab/

3. **SVDFeature**(http://svdfeature.apexlab.org/wiki/Main_Page)
 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/q96e33s4h383a6z1fu1budvy/SVD.png" width="200" height="200" alt="Librec Context" /></div>
 
 一个feature-based协同过滤和排序工具，由上海交大Apex实验室开发，代码质量较高。在KDD Cup 2012中获得第一名，KDD Cup 2011中获得第三名，相关论文 发表在2012的JMLR中。SVDFeature包含一个很灵活的Matrix Factorization推荐框架，能方便的实现SVD、SVD++等方法, 是单模型推荐算法中精度最高的一种。SVDFeature代码精炼，可以用 相对较少的内存实现较大规模的单机版矩阵分解运算。另外含有Logistic regression的model，可以很方便的用来进行ensemble。

4. **LibMF**(http://www.csie.ntu.edu.tw/~cjlin/libmf/)
 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/2b2pkfgf49fezs2t2qo5tjp4/image_1bc7femdbe0uap72d22gk60q2t.png" width="400" height="400" alt="Librec Context" /></div>

 作者Chih-Jen Lin来自大名鼎鼎的台湾国立大学，他们在机器学习领域享有盛名，近年连续多届KDD-Cup竞赛上均获得优异成绩，并曾连续多年获得冠军。台湾大学的风格非常务实，业界常用的LibSVM，Liblinear等都是他们开发的，开源代码的效率和质量都非常高。

  LibMF在矩阵分解的并行化方面作出了很好的贡献，针对SGD（随即梯度下降）优化方法在并行计算中存在的locking problem和memory discontinuity问题，提出了一种 矩阵分解的高效算法FPSGD（Fast Parallel SGD），根据计算节点的个数来划分评分矩阵block，并分配计算节点。
  
5. **LibFM**(http://www.libfm.org/ )
 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/im03jy4byndpmtwsfrmt0u5i/image_1bc7fncn616jh1j5pejn1e1n181f3a.png" width="150" height="150" alt="Librec Context" /></div>

 作者是德国Konstanz大学的Steffen Rendle，他用LibFM同时玩转KDD Cup 2012 Track1和Track2两个子竞赛单元，都取得了很好的成绩，说明LibFM是非常管用的利器。
 
 LibFM是专门用于矩阵分解的利器，尤其是其中实现了MCMC（Markov Chain Monte Carlo）优化算法，比常见的SGD优化方法精度要高，但运算速度要慢一些。当然LibFM中还 实现了SGD、SGDA（Adaptive SGD）、ALS（Alternating Least Squares）等算法。
 
6. **Lenskit**(http://lenskit.org/ )
 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/189kr5wjl5lq310yl5edmhnt/image_1bc7frf461dg01ev2ai11s1lcq03n.png" width="350" height="350" alt="Librec Context" /></div>
这个Java开发的开源推荐系统，来自美国的明尼苏达大学的GroupLens团队，也是推荐领域知名的测试数据集Movielens的作者。

 该源码托管在GitHub上，https://github.com/grouplens/lenskit。 主要包含lenskit-api,lenskit-core, lenskit-knn,lenskit-svd,lenskit-slopone,lenskit-parent,lenskit-data- structures,lenskit-eval,lenskit-test等模块，主要实现了k-NN，SVD，Slope-One等 典型的推荐系统算法。

7. **EasyRec**(http://easyrec.org/ )
 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/scr4bcnji4vynw3bp778fuqp/image_1bc7g23tia4nfbldfi1us91gp044.png" width="250" height="250" alt="Librec Context" /></div>

 EasyRec是一个易集成、易扩展、功能强大且具有可视化管理的推荐系统，更像一个完整的推荐产品，包括了数据录入模块、管理模块、推荐挖掘、离线分析等。它可以同时给多个不同的网站提供推荐服务，通过tenant来区分不同的网站。架设EasyRec服务器，为网站申请tenant，通过tenant就可以很方便的集成到 网站中。

---



#7. **推荐系统案例（Case Study）**
##7.1 **Facebook如何向十亿人推荐东西**
作为全球排名第一的社交网站，Facebook利用分布式推荐系统来帮助用户找到他们可能感兴趣的页面、组、事件或者游戏等。Facebook在其官网公布了其推荐系统的原理、性能及使用情况。(https://code.facebook.com/posts/861999383875667/recommending-items-to-more-than-a-billion-people/)

Facebook中推荐系统所要面对的数据集包含了约1000亿个评分、超过10亿的用户以及数百万的物品。相比于著名的Netflix Prize ，Facebook的数据规模已经超过了它两个数据级。**如何在大数据规模情况下仍然保持良好性能已经成为世界级的难题**。为解决这一难题，Facebook团队使用一个分布式迭代和图像处理平台——**Apache Giraph**作为推荐系统的基础平台。
 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/7w25sur5so1gn30q2ycaijjb/image_1bc7m60ao7jj1sbr1jnp9ca13t64h.png" width="800" height="400" alt="Librec Context" /></div>
 
在工作原理方面，Facebook推荐系统采用的是流行的协同过滤技术。从数学角度而言，该问题就是根据用户-物品的评分矩阵中已知的值来预测未知的值。其求解过程通常采用**矩阵分解（Matrix Factorization, MF）方法**。MF方法把用户评分矩阵表达为用户矩阵和物品的乘积，用这些矩阵相乘的结果${R'}$来拟合原来的评分矩阵${R}$，使得二者尽量接近。如果把${R}$和${R'}$之间的距离作为优化目标,那么矩阵分解就变成了求最小值问题。

对大规模数据而言，求解过程将会十分耗时。为了降低时间和空间复杂度，一些从随机特征向量开始的迭代式算法被提出。这些迭代式算法渐渐收敛，可以在合理的时间内找到一个最优解。**随机梯度下降（Stochastic Gradient Descent, SGD）算法**就是其中之一，其已经成功的用于多个问题的求解。SGD基本思路是以随机方式遍历训练集中的数据，并给出每个已知评分的预测评分值。用户和物品特征向量的调整就沿着评分误差越来越小的方向迭代进行，直到误差到达设计要求。因此，SGD方法可以不需要遍历所有的样本即可完成特征向量的求解。交替最小二乘法（Alternating Least Square, ALS）是另外一个迭代算法。其基本思路为交替固定用户特征向量和物品特征向量的值，不断的寻找局部最优解直到满足求解条件。

为了利用上述算法解决Facebook推荐系统的问题，原本Giraph中的标准方法就需要进行改变。之前，Giraph的标准方法是把用户和物品都当作为图中的顶点、已知的评分当作边。那么，SGD或ALS的迭代过程就是遍历图中所有的边，发送用户和物品的特征向量并进行局部更新。该方法存在若干重大问题。首先，迭代过程会带来巨大的网络通信负载。由于迭代过程需要遍历所有的边，一次迭代所发送的数据量就为边与特征向量个数的乘积。假设评分数为1000亿、特征向量为100对，每次迭代的通信数据量就为80TB。其次，物品流行程度的不同会导致图中节点度的分布不均匀。该问题可能会导致内存不够或者引起处理瓶颈。假设一个物品有1000亿个评分、特征向量同样为100对，该物品对应的一个点在一次迭代中就需要接收80GB的数据。最后，Giraph中并没有完全按照公式中的要求实现SGD算法。真正实现中，每个点都是利用迭代开始时实际收到的特征向量进行工作，而并非全局最新的特征向量。

综合以上可以看出，Giraph中最大的问题就在于每次迭代中都需要把更新信息发送到每一个顶点。为了解决这个问题，Facebook发明了一种利用**work-to-work**信息传递的高效、便捷方法。该方法把原有的图划分为了由若干work构成的一个圆。每个worker都包含了一个物品集合和若干用户。在每一步，相邻的worker沿顺时针方法把包含物品更新的信息发送到下游的worker。这样，每一步都只处理了各个worker内部的评分，而经过与worker个数相同的步骤后，所有的评分也全部都被处理。该方法实现了通信量与评分数无关，可以明显减少图中数据的通信量。而且，标准方法中节点度分布不均匀的问题也因为物品不再用顶点来表示而不复存在。为了进一步提高算法性能，Facebook把**SGD和ALS两个算法进行了揉合，提出了旋转混合式求解方法**。
 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/76xss0fj964sl4713pxtf2ve/image_1bc7miss81iff1jc0trlhu11avk4u.png" width="800" height="400" alt="Librec Context" /></div>
 
接下来，Facebook在运行实际的**A/B测试**之间对推荐系统的性能进行了测量。首先，通过输入一直的训练集，推荐系统对算法的参数进行微调来提高预测精度。然后，系统针对测试集给出评分并与已知的结果进行比较。Facebook团队从物品平均评分、前1/10/100物品的评分精度、所有测试物品的平均精度等来评估推荐系统。此外，均方根误差（Root Mean Squared Error, RMSE）也被用来记录单个误差所带来的影响。

此外，即使是采用了分布式计算方法，Facebook仍然不可能检查每一个用户/物品对的评分。团队需要寻找更快的方法来获得每个用户排名前K的推荐物品，然后再利用推荐系统计算用户对其的评分。其中一种可能的解决方案是采用**ball tree数据结构**来存储物品向量。ball tree结构可以实现搜索过程10-100倍的加速，使得物品推荐工作能够在合理时间内完成。另外一个能够近似解决问题的方法是根据物品特征向量对物品进行分类。这样，寻找推荐评分就划分为寻找最推荐的物品群和在物品群中再提取评分最高的物品两个过程。该方法在一定程度上会降低推荐系统的可信度，却能够加速计算过程。

最后，Facebook给出了一些实验的结果。在2014年7月，Databricks公布了在Spark上实现ALS的性能结果。Facebook针对Amazon的数据集，基于Spark MLlib进行标准实验，与自己的旋转混合式方法的结果进行了比较。实验结果表明，Facebook的系统比标准系统要快10倍左右。而且，前者可以轻松处理超过1000亿个评分。

目前，该方法已经用了Facebook的多个应用中，包括页面或者组的推荐等。为了能够减小系统负担，Facebook只是把度超过100的页面和组考虑为候选对象。而且，在初始迭代中，Facebook推荐系统把用户喜欢的页面/加入的组以及用户不喜欢或者拒绝加入的组都作为输入。此外，Facebook还利用基于ALS的算法，从用户获得间接的反馈。未来，Facebook会继续对推荐系统进行改进，包括利用社交图和用户连接改善推荐集合、自动化参数调整以及尝试比较好的划分机器等。
##7.2 **Netflix公布个性化和推荐系统架构**
作为一家在线影片租赁提供商，Netflix能够提供超大数量的DVD，而且能够让顾客快速方便的挑选影片，同时免费递送，已经连续五次被评为顾客最满意的网站。Netflix的推荐和个性化功能在业界以精准著称，并公布了自己在这方面的系统架构。（http://techblog.netflix.com/2013/03/system-architectures-for.html）

 <div  align="center"> <img src="http://static.zybuluo.com/Jessy923/xpbhfwlt33fbiwd9bnt0hiyp/image_1bc7n697g1l1ds96g0ml85ndc5b.png" width="800" height="400" alt="Librec Context" /></div>
 
Netflix公布了他们的系统框架图，并对其中的组件和处理过程进行了解释：
>对于数据，最简单的方法是存下来，留作后续离线处理，这就是我们用来管理离线作业（Offline jobs）的部分架构。计算可以以离线、接近在线或是在线方式完成。
>
 - 在线计算（Online computation）能更快地响应最近的事件和用户交互，但必须实时完成。这会限制使用算法的复杂性和处理的数据量。
 - 离线计算（Offline computation）对于数据数量和算法复杂度限制更少，因为它以批量方式完成，没有很强的时间要求。不过，由于没有及时加入最新的数据，所以很容易过时。个性化架构的关键问题，就是如何以无缝方式结合、管理在线和离线计算过程。
 - 接近在线计算（Nearline computation）介于两种方法之间，可以执行类似于在线计算的方法，但又不必以实时方式完成。
 - 模型训练（Model training）是另一种计算，使用现有数据来产生模型，便于以后在对实际结果计算中使用。
 - 另一块架构是如何使用事件和数据分发系统（Event and Data Distribution）处理不同类型的数据和事件。与之相关的问题，是如何组合在离线、接近在线和在线之间跨越的不同的信号和模型（Signals and Models）。最后，需要找出如何组合推荐结果（Recommendation Results），让其对用户有意义。





#**参考资源**
<以上稿件在参考以下资源的基础上撰写而成>：

 - https://www.slideshare.net/xamat/recommender-systems-machine-learning-summer-school-2014-cmu
 - http://www.open-open.com/lib/view/open1433322554291.html
 - http://www.infoq.com/cn/news/2015/06/facebook-recommender-system
 - https://code.facebook.com/posts/861999383875667/recommending-items-to-more-than-a-billion-people/
 - http://www.infoq.com/cn/news/2015/12/Algorithm-case-10
 - https://github.com/mendeley/mrec
 - https://github.com/muricoca/crab
 - https://github.com/ocelma/python-recsys
 - https://github.com/markusweimer/cofirank
 - https://github.com/jegonzal/PowerGraph
 - https://github.com/hernad/easyrec
 - https://github.com/lenskit/lenskit
 - https://github.com/apache/mahout
 - https://github.com/davidcelis/recommendable
 - 《推荐系统实践》（项亮 著）

  <img src="http://static.zybuluo.com/Jessy923/cx7822i6c5qrwrnz45i3u2m3/image_1bc7pu7c912f513fhgrm1n2i6bh6v.png" width="300" height="300" alt="Librec Context" />

 - 《推荐系统》（Dietmar Jannach等 著，蒋凡 译）

 <img src="http://static.zybuluo.com/Jessy923/u05yury7njssrq8arx7y3qxk/image_1bc7q07kh1on615fhg38ua713hr7c.png" width="300" height="300" alt="Librec Context" />

 - 《用户网络行为画像》（牛温佳等 著）

 <img src="http://static.zybuluo.com/Jessy923/anke6lfdm2kdnx5vz8d37u5h/image_1bc7q1hnim3o1pt91jfhkjg8k7p.png" width="300" height="300" alt="Librec Context" />
 
 - 《Recommender Systems Handbook》（Paul B·Kantor等 著）

 <img src="http://static.zybuluo.com/Jessy923/r8xxzivjd723cgs0w999vqpr/image_1bc7qaj2i17f51rkc6j711er1qd38f.png" width="300" height="300" alt="Librec Context" />
